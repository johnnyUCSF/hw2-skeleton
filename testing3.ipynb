{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from hw2skeleton import cluster\n",
    "from hw2skeleton import io\n",
    "import os\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "from statistics import mean \n",
    "from scipy.stats.mstats import gmean\n",
    "import pandas as pd\n",
    "import math\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#####################overall framework is distilling the data into simpler pieces in stages\n",
    "#####################in the end the reduced information is used to calculate similarity\n",
    "\n",
    "###########First calculate for each residue two pieces of information:\n",
    "####1) centroid of residue (simplifies all the atomic positions of side chains etc)\n",
    "####2) class of amino acid (ie polar amphipathic etc)\n",
    "###########then reduce the information from residues to properties of active site:\n",
    "####1) most frequent amino acid class\n",
    "####2) ratio of first longest dimension / second longest dimension\n",
    "####3) ratio of first longest dimension / third longest dimension\n",
    "###########then combine these three properties into a similarity score with each one being weighted \n",
    "\n",
    "def calc_cent(residue):\n",
    "    ######pull out only the coordinates from the residue and calculate the centroid of the residue\n",
    "    tmp_activesite = []\n",
    "    for atom in residue.atoms:\n",
    "        tmp_atm = []\n",
    "        for coord in atom.coords:\n",
    "            tmp_atm.append(coord)\n",
    "        tmp_activesite.append(tmp_atm)\n",
    "    tmp_activesite = np.array(tmp_activesite)\n",
    "    ######calc centroid in 3d\n",
    "    length = tmp_activesite.shape[0]\n",
    "    sum_x = np.sum(tmp_activesite[:, 0])\n",
    "    sum_y = np.sum(tmp_activesite[:, 1])\n",
    "    sum_z = np.sum(tmp_activesite[:, 2])\n",
    "    return sum_x/length, sum_y/length, sum_z/length\n",
    "\n",
    "def calc_class(residue):\n",
    "    #####classify residue by type of amino acid class it falls into: charged, polar, amphipathic, hydrophobic\n",
    "    #####returns a string\n",
    "    classdict = {\n",
    "        'ARG': 'c', \n",
    "         'LYS': 'c', \n",
    "         'ASP': 'c', \n",
    "         'GLU': 'c', \n",
    "         'GLN': 'p',\n",
    "         'ASN': 'p', \n",
    "         'HIS': 'p', \n",
    "         'SER': 'p', \n",
    "         'THR': 'p', \n",
    "         'TYR': 'p', \n",
    "         'CYS': 'p', \n",
    "         'TRP': 'a', \n",
    "         'TYR': 'a', \n",
    "         'MET': 'a', \n",
    "         'ALA': 'h', \n",
    "         'ILE': 'h', \n",
    "         'LEU': 'h', \n",
    "         'PHE': 'h', \n",
    "         'VAL': 'h',\n",
    "         'PRO': 'h',\n",
    "         'GLY': 'h'}\n",
    "    ######check if labelled correctly\n",
    "    if residue.type in classdict:\n",
    "        ######if so return the class \n",
    "        return classdict.get(residue.type)\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "def calc_seq(activesite):\n",
    "    final_string = ''\n",
    "    for residue in activesite.residues:\n",
    "        final_string += (calc_class(residue))\n",
    "    return(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_similarity(site_a, site_b):\n",
    "#####################overall framework is distilling the data into simpler pieces in stages\n",
    "#####################in the end the reduced information is used to calculate similarity\n",
    "\n",
    "###########First calculate for each residue two pieces of information:\n",
    "####1) centroid of residue (simplifies all the atomic positions of side chains etc)\n",
    "####2) class of amino acid (ie polar amphipathic etc)\n",
    "###########then reduce the information from residues to properties of active site:\n",
    "####1) most frequent amino acid class\n",
    "####2) ratio of first longest dimension / second longest dimension\n",
    "####3) ratio of first longest dimension / third longest dimension\n",
    "###########then combine these three properties into a similarity score with each one being weighted \n",
    "    \"\"\"\n",
    "    Compute the similarity between two given ActiveSite instances.\n",
    "\n",
    "    Input: two ActiveSite instances\n",
    "    Output: the similarity between them (a floating point number)\n",
    "    \"\"\"\n",
    "    similarity = 0.0\n",
    "    #########simplify data to type of amino acid\n",
    "    seq_a = calc_seq(site_a)\n",
    "    seq_b = calc_seq(site_b)\n",
    "    #########calculate alignment score\n",
    "    alignments = pairwise2.align.globalms(seq_a, seq_b, 2, -1, -.5, -.1)\n",
    "    best_score = alignments[0][2]\n",
    "    max_score = min([len(seq_a),len(seq_b)])*2\n",
    "    percent_score = float(best_score)/float(max_score)\n",
    "    ####check to make sure score is within range\n",
    "    if percent_score < 0:\n",
    "        percent_score = 0\n",
    "    if percent_score > 1:\n",
    "        percent_score = 1\n",
    "    return percent_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6000000000000006"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_a = os.path.join(\"data\", \"10701.pdb\")\n",
    "filename_b = os.path.join(\"data\", \"17526.pdb\")\n",
    "\n",
    "site_a = io.read_active_site(filename_a)\n",
    "site_b = io.read_active_site(filename_b)\n",
    "\n",
    "compute_similarity(site_a,site_b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_closest(centroid_list,inputs):\n",
    "    closest_vector = []\n",
    "    #####calculate distances between each item and centroids\n",
    "    for item in inputs:\n",
    "        sim_vector = []\n",
    "        ###loop through centroids\n",
    "        for centroid in centroid_list:\n",
    "            ###calculate similarity and append to similarity vector for that item\n",
    "            sim_vector.append(cluster.compute_similarity(centroid,site))\n",
    "        #####find most similar centroid for that point\n",
    "        closest_vector.append(sim_vector.index(max(sim_vector)))\n",
    "    ######returns a vector same size as table indicating which centroid it is closest to\n",
    "    return(closest_vector)\n",
    "\n",
    "def find_newcentroid(closest_vector,inputs,n_clusters):\n",
    "    #####initialize\n",
    "    clusters = []\n",
    "    for i in range(n_clusters):\n",
    "        clusters.append([])\n",
    "    ####group by cluster membership\n",
    "    for item in closest_vector:\n",
    "        clusters[item].append(inputs[i])\n",
    "    #####okay so now that they are split up by cluster find the point with smallest intracluster distance\n",
    "    new_centroids = []\n",
    "    ##this is for intracluster distance\n",
    "    new_dists = []\n",
    "    for k in clusters:\n",
    "        dists = []\n",
    "        for item in k:\n",
    "            ###sum intracluster distance for each point\n",
    "            total_dist = 0.0\n",
    "            for site_c in k:\n",
    "                row += cluster.compute_similarity(site_r,site_c)\n",
    "            ###write total distance to dists vector\n",
    "            dists.append(row_sum)\n",
    "        #####find point with smallest distance; this is the new centroid\n",
    "        new_cent = dists.index(min(dists))\n",
    "        new_centroids.append(k[new_cent])\n",
    "    ###returns vector of size N_clusters indicating new centroids\n",
    "    return(new_centroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "############################K-means implementation\n",
    "####import data\n",
    "active_sites = io.read_active_sites('/Users/johnny/Desktop/class/hw2-skeleton/data')\n",
    "test = active_sites[0:10]\n",
    "####define k \n",
    "    n_clusters = 4\n",
    "    ###Randomize cluster centroids\n",
    "    rnd_nums = random.sample(range(0, len(test)-1), n_clusters)\n",
    "    centroids = []\n",
    "    for num in rnd_nums:\n",
    "        centroids.append(test[num])\n",
    "    ###Main\n",
    "    i = 0\n",
    "    while i < 50:\n",
    "        ###return vector indicating labels\n",
    "        labels = find_closest(centroids,test)\n",
    "        ###Find New Centroids\n",
    "        new_centroids, new_dists = find_newcentroid(labels,test,n_clusters)\n",
    "        ###check if final centers have been reached\n",
    "        if np.all(centroids == new_centroids):\n",
    "            break\n",
    "        ###update centroids\n",
    "        centroids = new_centroids\n",
    "        i+=1\n",
    "        ###\n",
    "        print(i)\n",
    "        print('new_dists:',new_dists)\n",
    "        print('new_dists:',gmean(new_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#############Hierarchical Implementation\n",
    "###########K-nearest Neighbor\n",
    "test = active_sites[0:10]\n",
    "####\n",
    "def getNeighbors(testSet, k):\n",
    "    distances = []\n",
    "    closest_neighbors = []\n",
    "    for item1 in testSet:\n",
    "        ####get the distance of this point to each other point\n",
    "        item1_distances = []\n",
    "        item1_ids = []\n",
    "        for item2 in testSet:\n",
    "            ####don't calculate self\n",
    "            if item2 != item1:\n",
    "                dist = cluster.compute_similarity(item1,item2)\n",
    "                item1_distances.append(dist)\n",
    "                item1_ids.append(item2)\n",
    "        ####find the closest neighbor NOT in the original cluster\n",
    "        neighbor = item1_ids[item1_distances.index(min(item1_distances))]\n",
    "        closest_neighbors.append(neighbor)\n",
    "    return(closest_neighbors)\n",
    "\n",
    "def calc_distmatrix(testSet):\n",
    "    DistMatrix = []\n",
    "    for item1 in testSet:\n",
    "        row = []\n",
    "        for item2 in testSet:\n",
    "            dist = cluster.compute_similarity(item1,item2)\n",
    "            row.append(dist)\n",
    "        DistMatrix.append(row)\n",
    "    return DistMatrix\n",
    "\n",
    "\n",
    "neighbors = getNeighbors(test,2)\n",
    "print(neighbors)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calc_distmatrix(testSet):\n",
    "    DistMatrix = []\n",
    "    for item1 in testSet:\n",
    "        row = []\n",
    "        for item2 in testSet:\n",
    "            dist = cluster.compute_similarity(item1,item2)\n",
    "            row.append(dist)\n",
    "        DistMatrix.append(row)\n",
    "    return DistMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 136 active sites\n",
      "0 7 [7, 7, 6, 9, 5, 4, 4, 1, 4, 3] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "1 7 [7, 7, 6, 9, 5, 4, 4, 1, 4, 3] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "2 6 [7, 7, 6, 9, 5, 4, 4, 1, 4, 3] [0, 1, 2, 3, 4, 5, 6, 1, 8, 9]\n",
      "3 9 [7, 7, 6, 9, 5, 4, 4, 1, 4, 3] [0, 1, 2, 3, 4, 5, 6, 1, 8, 9]\n",
      "4 5 [7, 7, 6, 9, 5, 4, 4, 1, 4, 3] [0, 1, 2, 3, 4, 5, 6, 1, 8, 3]\n",
      "5 4 [7, 7, 6, 9, 5, 4, 4, 1, 4, 3] [0, 1, 2, 3, 4, 4, 6, 1, 8, 3]\n",
      "6 4 [7, 7, 6, 9, 5, 4, 4, 1, 4, 3] [0, 1, 2, 3, 4, 4, 6, 1, 8, 3]\n",
      "7 1 [7, 7, 6, 9, 5, 4, 4, 1, 4, 3] [0, 1, 2, 3, 4, 4, 6, 1, 8, 3]\n",
      "8 4 [7, 7, 6, 9, 5, 4, 4, 1, 4, 3] [0, 1, 2, 3, 4, 4, 6, 1, 8, 3]\n",
      "9 3 [7, 7, 6, 9, 5, 4, 4, 1, 4, 3] [0, 1, 2, 3, 4, 4, 6, 1, 8, 3]\n",
      "[0, 1, 2, 3, 4, 4, 6, 1, 8, 3]\n",
      "0 1 [1, 0, 6, 4, 8, 8, 4, 0, 4, 4] [0, 1, 2, 3, 4, 4, 6, 1, 8, 3]\n",
      "1 0 [1, 0, 6, 4, 8, 8, 4, 0, 4, 4] [0, 0, 2, 3, 4, 4, 6, 0, 8, 3]\n",
      "2 6 [1, 0, 6, 4, 8, 8, 4, 0, 4, 4] [0, 0, 2, 3, 4, 4, 6, 0, 8, 3]\n",
      "3 4 [1, 0, 6, 4, 8, 8, 4, 0, 4, 4] [0, 0, 2, 3, 4, 4, 6, 0, 8, 3]\n",
      "4 8 [1, 0, 6, 4, 8, 8, 4, 0, 4, 4] [0, 0, 2, 3, 4, 4, 6, 0, 8, 3]\n",
      "5 8 [1, 0, 6, 4, 8, 8, 4, 0, 4, 4] [0, 0, 2, 3, 4, 4, 6, 0, 4, 3]\n",
      "6 4 [1, 0, 6, 4, 8, 8, 4, 0, 4, 4] [0, 0, 2, 3, 4, 4, 6, 0, 4, 3]\n",
      "7 0 [1, 0, 6, 4, 8, 8, 4, 0, 4, 4] [0, 0, 2, 3, 4, 4, 6, 0, 4, 3]\n",
      "8 4 [1, 0, 6, 4, 8, 8, 4, 0, 4, 4] [0, 0, 2, 3, 4, 4, 6, 0, 4, 3]\n",
      "9 4 [1, 0, 6, 4, 8, 8, 4, 0, 4, 4] [0, 0, 2, 3, 4, 4, 6, 0, 4, 3]\n",
      "[0, 0, 2, 3, 4, 4, 6, 0, 4, 3]\n",
      "0 4 [4, 4, 6, 4, 6, 6, 4, 4, 6, 4] [0, 0, 2, 3, 4, 4, 6, 0, 4, 3]\n",
      "1 4 [4, 4, 6, 4, 6, 6, 4, 4, 6, 4] [0, 0, 2, 3, 4, 4, 6, 0, 4, 3]\n",
      "2 6 [4, 4, 6, 4, 6, 6, 4, 4, 6, 4] [0, 0, 2, 3, 4, 4, 6, 0, 4, 3]\n",
      "3 4 [4, 4, 6, 4, 6, 6, 4, 4, 6, 4] [0, 0, 2, 3, 4, 4, 6, 0, 4, 3]\n",
      "4 6 [4, 4, 6, 4, 6, 6, 4, 4, 6, 4] [0, 0, 2, 3, 4, 4, 6, 0, 4, 3]\n",
      "5 6 [4, 4, 6, 4, 6, 6, 4, 4, 6, 4] [0, 0, 2, 3, 4, 4, 4, 0, 4, 3]\n",
      "6 4 [4, 4, 6, 4, 6, 6, 4, 4, 6, 4] [0, 0, 2, 3, 4, 4, 4, 0, 4, 3]\n",
      "7 4 [4, 4, 6, 4, 6, 6, 4, 4, 6, 4] [0, 0, 2, 3, 4, 4, 4, 0, 4, 3]\n",
      "8 6 [4, 4, 6, 4, 6, 6, 4, 4, 6, 4] [0, 0, 2, 3, 4, 4, 4, 0, 4, 3]\n",
      "9 4 [4, 4, 6, 4, 6, 6, 4, 4, 6, 4] [0, 0, 2, 3, 4, 4, 4, 0, 4, 3]\n",
      "[0, 0, 2, 3, 4, 4, 4, 0, 4, 3]\n",
      "0 4 [4, 4, 4, 4, 0, 0, 0, 4, 0, 4] [0, 0, 2, 3, 4, 4, 4, 0, 4, 3]\n",
      "1 4 [4, 4, 4, 4, 0, 0, 0, 4, 0, 4] [0, 0, 2, 3, 0, 0, 0, 0, 0, 3]\n",
      "2 4 [4, 4, 4, 4, 0, 0, 0, 4, 0, 4] [0, 0, 2, 3, 0, 0, 0, 0, 0, 3]\n",
      "3 4 [4, 4, 4, 4, 0, 0, 0, 4, 0, 4] [0, 0, 2, 3, 0, 0, 0, 0, 0, 3]\n",
      "4 0 [4, 4, 4, 4, 0, 0, 0, 4, 0, 4] [0, 0, 2, 3, 0, 0, 0, 0, 0, 3]\n",
      "5 0 [4, 4, 4, 4, 0, 0, 0, 4, 0, 4] [0, 0, 2, 3, 0, 0, 0, 0, 0, 3]\n",
      "6 0 [4, 4, 4, 4, 0, 0, 0, 4, 0, 4] [0, 0, 2, 3, 0, 0, 0, 0, 0, 3]\n",
      "7 4 [4, 4, 4, 4, 0, 0, 0, 4, 0, 4] [0, 0, 2, 3, 0, 0, 0, 0, 0, 3]\n",
      "8 0 [4, 4, 4, 4, 0, 0, 0, 4, 0, 4] [0, 0, 2, 3, 0, 0, 0, 0, 0, 3]\n",
      "9 4 [4, 4, 4, 4, 0, 0, 0, 4, 0, 4] [0, 0, 2, 3, 0, 0, 0, 0, 0, 3]\n",
      "[0, 0, 2, 3, 0, 0, 0, 0, 0, 3]\n",
      "0 3 [3, 3, 0, 0, 3, 3, 3, 3, 3, 0] [0, 0, 2, 3, 0, 0, 0, 0, 0, 3]\n",
      "1 3 [3, 3, 0, 0, 3, 3, 3, 3, 3, 0] [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "2 0 [3, 3, 0, 0, 3, 3, 3, 3, 3, 0] [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "3 0 [3, 3, 0, 0, 3, 3, 3, 3, 3, 0] [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "4 3 [3, 3, 0, 0, 3, 3, 3, 3, 3, 0] [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "5 3 [3, 3, 0, 0, 3, 3, 3, 3, 3, 0] [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "6 3 [3, 3, 0, 0, 3, 3, 3, 3, 3, 0] [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "7 3 [3, 3, 0, 0, 3, 3, 3, 3, 3, 0] [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "8 3 [3, 3, 0, 0, 3, 3, 3, 3, 3, 0] [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "9 0 [3, 3, 0, 0, 3, 3, 3, 3, 3, 0] [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "0 2 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "1 2 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2 0 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "3 2 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "4 2 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "5 2 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "6 2 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "7 2 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "8 2 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "9 2 [2, 2, 0, 2, 2, 2, 2, 2, 2, 2] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "######data structures\n",
    "####test contains the active sites in an array\n",
    "####clust contains the cluster membership in an array\n",
    "####\n",
    "active_sites = io.read_active_sites('/Users/johnny/Desktop/class/hw2-skeleton/data')\n",
    "\n",
    "test = active_sites[0:10]\n",
    "def agglomerative(test):\n",
    "    #######this is agglomerative\n",
    "    ######this is an array of memberships which is returned\n",
    "    clust_all = []\n",
    "    ######initialize clust, each point is its own cluster to start\n",
    "    clust = []\n",
    "    i = 0\n",
    "    for item in test:\n",
    "        clust.append(i)\n",
    "        i+=1\n",
    "    #####final output will be an array of clusters\n",
    "\n",
    "    ######calculate distance matrix\n",
    "    DistMatrix = calc_distmatrix(test)\n",
    "    ######Begin agglomeration\n",
    "    while True:\n",
    "        closest_clust = []\n",
    "        for clust_id in clust:\n",
    "            #####define self and other because we want to find closest neighbor not in same cluster\n",
    "            self_clust = []\n",
    "            other_clust = []\n",
    "            #####iterate through test to assign self and other clusters; appending index for easy access\n",
    "            for i in range(len(test)):\n",
    "                if clust[i] == clust_id:\n",
    "                    self_clust.append(i)\n",
    "                else:\n",
    "                    other_clust.append(i)\n",
    "            #####now use distance matrix to find those points closest to each cluster (find closest neighbors)\n",
    "            ##min_val holds current minimum, ind_self = index of that item in self, ind_other = index of that item in other\n",
    "            min_val = -1 ##similarity is 0<sim<1\n",
    "            ind_self = math.inf\n",
    "            ind_other = math.inf\n",
    "            for row in range(len(DistMatrix)):\n",
    "                ####compare distances between those in and those out of self cluster\n",
    "                if row in self_clust:\n",
    "                    for col in range(len(DistMatrix)):\n",
    "                        if col not in self_clust:\n",
    "                            ###compare max sim\n",
    "                            if DistMatrix[row][col] > min_val:\n",
    "                                ##update\n",
    "                                min_val = DistMatrix[row][col]\n",
    "                                ind_self = row\n",
    "                                ind_other = col\n",
    "            ####remember which cluster was the closest; store the cluster ID!!\n",
    "            closest_clust.append(clust[ind_other])\n",
    "        #####go through clusters and combine clusters based on closest neighbors\n",
    "        ####neighbors have to be reciprocal; this is written out long form for my own clarity\n",
    "        for i in range(len(closest_clust)):\n",
    "            self_index = i\n",
    "            neighbor_index = closest_clust[i] ##index of neighbor is stored here\n",
    "            self_neighbor = closest_clust[i] ##index of neighbor is stored here\n",
    "            neighbor_neighbor = closest_clust[closest_clust[i]] \n",
    "            if self_index == neighbor_neighbor:\n",
    "                ###update clusters\n",
    "                self_cluster_id = clust[self_index]\n",
    "                neighbor_cluster_id = clust[neighbor_index]\n",
    "                ##find neighbor clusters and update to self cluster id\n",
    "                for j in range(len(clust)):\n",
    "                    if (clust[j] == neighbor_cluster_id):\n",
    "                        clust[j] = self_cluster_id\n",
    "        #####save cluster membership and number of clusters\n",
    "        clust_all.append(clust)\n",
    "        #####see if num sets == 1 yet\n",
    "        if len(set(clust)) == 1:\n",
    "            break\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.91214520996876347, 0.36403547508989237, 0.54501586304459726],\n",
       " [0.89313403416281467, 1.0, 0.3333333333333333, 0.41346003763254058],\n",
       " [0.61057433475226275, 0.57940750581593081, 1.0, 0.31218521860040938],\n",
       " [0.57614799227375313, 0.51216513190659252, 0.024976586830300018, 1.0]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DistMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for num in set(clust):\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def simple_hierarchical_clustering(distance_matrix, howmany):\n",
    "    site_names = distance_matrix.index.tolist()\n",
    "    clusters_number = distance_matrix.shape[0]\n",
    "    cldict = {x:set([x]) for x in site_names}\n",
    "    pairs_dict = {}\n",
    "    # get all the distances between pairs of points in convenient form\n",
    "    for p in site_names:\n",
    "    for q in site_names:\n",
    "    if p == q:\n",
    "    continue\n",
    "    pairs_dict[(p,q)] = distance_matrix.ix[p][q]\n",
    "\n",
    "    # sort the pairs by distance\n",
    "    sorted_pairs_dict = sorted(pairs_dict.items(), key=operator.itemgetter(1))\n",
    "    # iteratively combine them to clusters\n",
    "    for element in sorted_pairs_dict:\n",
    "    pair = element[0]\n",
    "    value = element[1]\n",
    "    if cldict[pair[0]] != cldict[pair[1]]:\n",
    "    clusters_number -= 1\n",
    "    cldict[pair[0]] = (cldict[pair[0]] | cldict[pair[1]])\n",
    "    for el in cldict[pair[0]]:\n",
    "    cldict[el] = cldict[pair[0]]\n",
    "    if clusters_number <= howmany:\n",
    "    break\n",
    "\n",
    "    clusters_set = set([frozenset(cldict[k]) for k in cldict])\n",
    "    return clusters_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def simple_hierarchical_clustering(distance_matrix, howmany):\n",
    "    site_names = distance_matrix.index.tolist()\n",
    "    clusters_number = distance_matrix.shape[0]\n",
    "    cldict = {x:set([x]) for x in site_names}\n",
    "    pairs_dict = {}\n",
    "    # get all the distances between pairs of points in convenient form\n",
    "    for p in site_names:\n",
    "        for q in site_names:\n",
    "            if p == q:\n",
    "                continue\n",
    "    pairs_dict[(p,q)] = distance_matrix.ix[p][q]\n",
    "\n",
    "    # sort the pairs by distance\n",
    "    sorted_pairs_dict = sorted(pairs_dict.items(), key=operator.itemgetter(1))\n",
    "    # iteratively combine them to clusters\n",
    "    for element in sorted_pairs_dict:\n",
    "    pair = element[0]\n",
    "    value = element[1]\n",
    "    if cldict[pair[0]] != cldict[pair[1]]:\n",
    "    clusters_number -= 1\n",
    "    cldict[pair[0]] = (cldict[pair[0]] | cldict[pair[1]])\n",
    "    for el in cldict[pair[0]]:\n",
    "    cldict[el] = cldict[pair[0]]\n",
    "    if clusters_number <= howmany:\n",
    "    break\n",
    "\n",
    "    clusters_set = set([frozenset(cldict[k]) for k in cldict])\n",
    "    return clusters_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Classify(nItem, k, Items): \n",
    "    if(k > len(Items)): \n",
    "          \n",
    "        # k is larger than list \n",
    "        # length, abort \n",
    "        return \"k larger than list length\"; \n",
    "      \n",
    "    # Hold nearest neighbors. \n",
    "    # First item is distance,  \n",
    "    # second class \n",
    "    neighbors = []; \n",
    "  \n",
    "    for item in Items: \n",
    "        \n",
    "        # Find Euclidean Distance \n",
    "        distance = EuclideanDistance(nItem, item); \n",
    "  \n",
    "        # Update neighbors, either adding \n",
    "        # the current item in neighbors  \n",
    "        # or not. \n",
    "        neighbors = UpdateNeighbors(neighbors, item, distance, k); \n",
    "  \n",
    "    # Count the number of each \n",
    "    # class in neighbors \n",
    "    count = CalculateNeighborsClass(neighbors, k); \n",
    "  \n",
    "    # Find the max in count, aka the \n",
    "    # class with the most appearances. \n",
    "    return FindMax(count); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test = [1,2,0]\n",
    "\n",
    "print(test.index(min(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Step 1 - Pick K random points as cluster centers called centroids.\n",
    "Step 2 - Assign each x_ix \n",
    "i\n",
    "​\t  to nearest cluster by calculating its distance to each centroid.\n",
    "Step 3 - Find new cluster center by taking the average of the assigned points.\n",
    "Step 4 - Repeat Step 2 and 3 until none of the cluster assignments change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_vals = []\n",
    "y_vals = []\n",
    "z_vals = []\n",
    "####pull out values individually\n",
    "for residue in cent_b:\n",
    "    x_vals.append(residue[0])\n",
    "    y_vals.append(residue[1])\n",
    "    z_vals.append(residue[2])\n",
    "####calc distance in each dimension\n",
    "dists = []\n",
    "dists.append(max(x_vals)-min(x_vals)),\n",
    "dists.append(max(y_vals)-min(y_vals)),\n",
    "dists.append(max(z_vals)-min(z_vals))\n",
    "print(dists)\n",
    "#####calc ratios of distances\n",
    "dists = dists.sort()\n",
    "ratio1to2 = dists[2]/dists[0]\n",
    "ratio1to3 = dists[2]/dists[1]\n",
    "print(ratio1to2)\n",
    "print(ratio1to3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "1.70394823498\n",
    "1.43196483847"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cent_b[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dists = distance.cdist(cent_b, cent_b, 'euclidean')\n",
    "for dist in dists:\n",
    "    print(dist)\n",
    "    print('okay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "activesite_a.residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "activesite_b.residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "activesite_b.residues[0].atoms[0].coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "activesite_b.residues[0].atoms[2].coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "activesite_b.residues[0].atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "activesite_b.residues[1].atoms[0].coords\n",
    "\n",
    "tmp_activesite = []\n",
    "for atom in activesite_b.residues[1].atoms:\n",
    "    tmp_atm = []\n",
    "    for coord in atom.coords:\n",
    "        tmp_atm.append(coord)\n",
    "    tmp_activesite.append(tmp_atm)\n",
    "tmp_activesite = np.array(tmp_activesite)\n",
    "tmp_activesite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "calc_centroid(activesite_b.residues[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for residue in activesite_b.residues:\n",
    "    print(calc_class(residue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "activesite_b.residues[1].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "activesite_b.residues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
